# PMFH
Learning Together Securely: Prototype-based Federated Multi-modal Hashing for Safe and Efficient Multi-modal Retrieval

### Introduction

With the proliferation of multi-modal data, efficient and secure multi-modal hashing retrieval has become a pressing research challenge, particularly due to concerns over data privacy during centralized processing. To address this, we propose Prototype-based Federated Multi-modal Hashing (PFMH), an innovative framework that seamlessly integrates federated learning with multi-modal hashing techniques. PFMH achieves fine-grained fusion of heterogeneous multi-modal data, enhancing retrieval accuracy while ensuring data privacy through prototype-based communication, thereby reducing communication costs and mitigating risks of data leakage. Furthermore, using a prototype completion strategy, PFMH tackles class imbalance and statistical heterogeneity in multi-modal data, improving model generalization and performance across diverse data distributions. Extensive experiments demonstrate the efficiency and effectiveness of PFMH within the federated learning framework, enabling distributed training for secure and precise multi-modal retrieval in real-world scenarios. The source codes of our method are available at: https://anonymous.4open.science/r/PMFH-17F9.


### Modal
Please find MODAL.pdf

### Recommendation
We recommend the following operating environment:
- Python == 3.6.x
- Pytorch == 1.8.1 + cu102
- Torchvision == 0.9.1 +cu102
- And other packages
- GPUs(NVIDIA RTX 3090).

### Datasets
https://pan.baidu.com/s/1ZoF80Q2ajxRWH4VPl7KEZA codeï¼šxpl3

### End
- bash flickr.sh


### Acknowledge
